{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Road to Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Standization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Standaridzation: Mean을 0으로 Variance를 1로 만들어주는 과정\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_col = df.select_dtypes(exclude=['int64', 'float64'])\n",
    "label = LabelEncoder()\n",
    "for column in categorical_col:\n",
    "    df[column] = label.fit_transform(df[column])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Defining Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        # print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        print(\"tn, fp, fn, tp\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}.ravel() \\n\")\n",
    "        p = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(y_train, pred), display_labels = ('positive', 'negative'))\n",
    "        p.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n",
    "        # tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
    "\n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_estimators = [100, 500, 1000, 1500]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [2, 3, 5]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4, 10]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "params_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_cv = GridSearchCV(rf_clf, params_grid, scoring=\"f1\", cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "\n",
    "rf_cv.fit(X_train, y_train)\n",
    "best_params = rf_cv.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "rf_clf = RandomForestClassifier(**best_params)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Isotonic Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncalibrated(X_train, X_test, y_train):\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    # predict probabilities\n",
    "    return model.predict_proba(X_test)[:, 1]\n",
    " \n",
    "def calibrated(X_train, X_test, y_train):\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    calibrated = CalibratedClassifierCV(model, method='isotonic')\n",
    "    calibrated.fit(X_train, y_train)\n",
    "    # predict probabilities\n",
    "    return calibrated.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncalibrated predictions\n",
    "yhat_uncalibrated = uncalibrated(X_train, X_test, y_train)\n",
    "\n",
    "# calibrated predictions\n",
    "yhat_calibrated = calibrated(X_train, X_test, y_train)\n",
    "\n",
    "# reliability diagrams\n",
    "fop_uncalibrated, mpv_uncalibrated = calibration_curve(y_test, yhat_uncalibrated, n_bins=10)\n",
    "fop_calibrated, mpv_calibrated = calibration_curve(y_test, yhat_calibrated, n_bins=10)\n",
    "\n",
    "# plot perfectly calibrated\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--', color='black')\n",
    "\n",
    "# plot model reliabilities\n",
    "pyplot.plot(mpv_uncalibrated, fop_uncalibrated, marker='.', label='Random Forest')\n",
    "pyplot.plot(mpv_calibrated, fop_calibrated, marker='.', label='Isotonic Calibration')\n",
    "plt.xlabel('Fraction belonging to positive class')\n",
    "plt.ylabel('Predicted probability of positive class')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
